# Project README file

## Part 1: Sockets
To send files, we can set the callback function of curl by setting `CURLOPT_WRITEFUNCTION` option to `send_chunk`. The `send_chunk` callback function has an extra argument which is set to `(void *)ctx`. After these setups, curl will call `send_chunk` to send data to client every time there is incoming data from libcurl.


The key problem is to get the status of this URL as well as file length before we literally send file. Luckily, we can tell curl to get header only by setting `CURLOPT_NOBODY` to `1`, and then use `curl_easy_getinfo` to read response code by `CURLINFO_RESPONSE_CODE` and file length by `CURLINFO_CONTENT_LENGTH_DOWNLOAD`. With all these information, the header is handy to be sent.

## Part 2: Shared Memory
### Command Channel
Message queue is used as communication method for commands between cache and proxy. It is better than socket because you do not have to worry about the starting order of both processes as message queue is independent of either process. This way we fulfilled requirement "Neither the cache daemon nor the proxy should crash if the other process is not started already."

Theoretically, two processes does not need to exist simultaneously, proxy process can send request and exit, and the request can be later read by cache process. This causes problem when the previous session exited without deleting all messages in the queue. To prevent this case, we need to clear the message queue using `msgctl(msqid, IPC_RMID, NULL);` command whenever a process exits.

The message struct contains information of segment(shmid and segment size) and path of request. Notice that shared memory information is passed by shmid(Shared Memory ID) rather than key generated by `ftok`. In [piazza](https://piazza.com/class/j6lk9ozisun4l1?cid=634), it is suggested that shmid() is not across processes, but it actually works and is also corroborated by https://stackoverflow.com/questions/23095076/is-shmid-returned-by-shmget-unique-across-processes . It is tested in my computer that even for different processes, the same key would generated the same shmid.

```c
///Message to request cache
typedef struct {
    long mtype;
    struct {            ///< Request Information
        ssize_t segsize;///< Shared memory segment size
        int shmid;      ///< Shared memory id
        char path[200]; ///< Path for requested file
    } req;
} req_msg;
```
The only information passed through message queue is shared memory information and path of request. It is an **one-way** message queue: proxy only send request and cache only accept request. Important information such as existence and length of requested file is transfered through data channel---shared memory. `request_cache()` in `handle_with_cache.c` is utility function to send cache request.

The message queue can be created by either process at its initialization by calling `getmsqid()`. If any process is killed, it will destroy the message queue by `destroy_msg()` and the other process will also exit right after any call of `msgrcv()` or `msgsnd()`. 

If the `simplecached` process is killed before `webproxy`, it won't exit until the beginning of another request. This issue is hard to solve because the handler function is not called until arrival of new request. A possible solution may be adding a watchdog thread which regularly check goodness of message queue and determine exit or not. In comparison, if webproxy is killed first then `simplecached` will exit instantly.

### Data Channel
The data channel is required to be implemented by shared memory, which is most efficient across IPCs for sending large files. As suggested by the original readme file, I create a pool of shared memory descriptors, which are pushed into a queue of free shared memory descriptors. 
To manage resources in this queue, shared memory segments can be allocated by `shm_pop()` and appended/returned by `shm_push()`

Synchronization is necessary for this queue, because there is data race when different threads are trying to get shared memory at the same time. To deal with this problem, I have used a mutex to lock the acess of queue, as well as condition variable `shm_available` to notify new available share memory.

The head of shared memory are synchronization variables, data length information, and transfer information including file length and read length . 
```c
typedef struct {
    pthread_mutex_t  m;
    pthread_cond_t  writable;
    pthread_cond_t  readable;
    ssize_t datalen;///< Data area length
    ssize_t filelen;///< File length
    ssize_t readlen;///< Data length to read this time(from data head)
    int status;     ///< Readable or writable
    char data[];    ///< Flexible array member used to transfer data
} cache;
```

+ All these data are initialized by calling `init_cache_block()`
+ With `readlen`, we clearly know how much data proxy should read for a specific transfer cycle. There are some situations that `readlen` is actually smaller than `datalen`. As an example, when we are transfering the end of a file it may be less than total length of data array! 
+ `data` is a flexible array member! Its length is stored in `datalen`, which equals to size of shared memory segment minus `sizeof(cache)`, i.e. `segsize - sizeof(cache)`.
+ File length is transfered through shared memory. A negative file length means invalid request and in this case proxy shoud return `GF_FILE_NOT_FOUND`.
+ Synchronization between proxy and cache
    + `m` is lock for any data access to shared memory
    + `status` is readable or writable with corresponding readable/writable signal to inform waiting proxy/cache thread, respectively.

Shared memory must have corresponding file. To solve this issue, temporary files `.shm-file-%d` are created in `init_cache_handlers()` and destroyed using `system('rm .shm-file-*')` in `clean_cache_handlers()`.

### Problems
+ There is type for msg queue and 0 type never works
+ `read` function is not thread safe. It caused program to pass partially in the test "Multi-threaded Cache test with simultaneous multi-threaded downloads (mixed file sizes)". After changed it to `pread` with the extra argument set by transfered bytes, this issue is solved.
    +  The reason why `read` is unsafe. Because every call of `read` attempts to increase file offset by the number of bytes read. If multiple threads are operating the same file descriptor, race condition happens.

## Known Limitations

If the cache server is killed when doing some transferring task, it may not delete shared memory resource taken by other threads. Because I am actually deleting all shared memory in the available shared memory queue, those unavailable ones will not be deleted. Improvement may be done by adding another static shared memory resource queue as an global inventory. 

## References
+ [Beej's Guide to Unix IPC](http://beej.us/guide/bgipc/output/html/multipage/index.html)
    + [Message Queues](http://beej.us/guide/bgipc/output/html/multipage/mq.html)
    + [Shared Memory Segments](http://beej.us/guide/bgipc/output/html/multipage/shm.html)

